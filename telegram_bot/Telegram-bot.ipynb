{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from model import ClassPredictor\n",
    "token = '????'\n",
    "import torch\n",
    "#from config import reply_texts\n",
    "reply_texts = {\n",
    "    'pred_answer': 'I predicted class with index {}. To show class name you will need to extract it from' +\n",
    "                   'dataloader you used while training'\n",
    "}\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from io import BytesIO\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.1.0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.transforms as transforms\n",
    "import torchvision.models as models\n",
    "\n",
    "from fastai.vision import load_learner, Image\n",
    "\n",
    "# В данном классе мы хотим полностью производить всю обработку картинок, которые поступают к нам из телеграма.\n",
    "# Это всего лишь заготовка, поэтому не стесняйтесь менять имена функций, добавлять аргументы, свои классы и\n",
    "# все такое.\n",
    "class ClassPredictor:\n",
    "    def __init__(self):\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.model = load_learner('./')\n",
    "        self.to_tensor = transforms.ToTensor()\n",
    "\n",
    "    def predict1(self, img_stream):\n",
    "        # Этот метод по переданным картинкам в каком-то формате (PIL картинка, BytesIO с картинкой\n",
    "        # или numpy array на ваш выбор). В телеграм боте мы получаем поток байтов BytesIO,\n",
    "        # а мы хотим спрятать в этот метод всю работу с картинками, поэтому лучше принимать тут эти самые потоки\n",
    "        # и потом уже приводить их к PIL, а потом и к тензору, который уже можно отдать модели.\n",
    "        # Не забудьте перенести все трансофрмации, которые вы использовали при тренировке\n",
    "        # Для этого будет удобно сохранить питоновский объект с ними в виде файла с помощью pickle,\n",
    "        # а потом загрузить здесь.\n",
    "\n",
    "        # Обработка картинки сейчас производится в методе process image, а здесь мы должны уже применить нашу\n",
    "        # модель и вернуть вектор предсказаний для нашей картинки\n",
    "\n",
    "        # Для наглядности мы сначала переводим ее в тензор, а потом обратно\n",
    "        #print(self.process_image(img_stream))\n",
    "        return self.model.predict(self.process_image(img_stream))[0]\n",
    "\n",
    "    # В predict используются некоторые внешние функции, их можно добавить как функции класса\n",
    "    # Если понятно, что функция является служебной и снаружи использоваться не должна, то перед именем функции\n",
    "    # принято ставить _ (выглядит это так: def _foo() )\n",
    "    # ниже пример того, как переносить методы\n",
    "    def process_image(self, img_stream):\n",
    "        # используем PIL, чтобы получить картинку из потока и изменить размер\n",
    "        image = PIL_Image.open(img_stream).resize((256, 256))\n",
    "        # переводим картинку в тензор и оборачиваем в объект Image, который использует fastai у себя внутри\n",
    "        image = Image(self.to_tensor(image))\n",
    "        \n",
    "        return image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Serg\\Anaconda3\\lib\\site-packages\\torch\\serialization.py:454: SourceChangeWarning: source code of class 'fastai.layers.AdaptiveConcatPool2d' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "C:\\Users\\Serg\\Anaconda3\\lib\\site-packages\\torch\\serialization.py:454: SourceChangeWarning: source code of class 'fastai.layers.Flatten' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n"
     ]
    }
   ],
   "source": [
    "model = ClassPredictor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text (bot,update):\n",
    "    chat_id = update.message.chat_id\n",
    "    print(update)\n",
    "    ans = 'kk'\n",
    "    if(update['message']['text'] == \"start\" or update['message']['text'] == \"help\"):\n",
    "        ans = 'Привет, дорогой друг, рады что ты к нам загленул. Этот бот умеет классифицировать ' + 'овощи, фрукты и ягоды. Просто пришли мне картинку и я скажу что это. '\n",
    "    else :\n",
    "        ans = 'я тебя не понимаю пришли help или картинку'\n",
    "    update.message.reply_text(ans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def send_prediction_on_photo(bot, update):\n",
    "    chat_id = update.message.chat_id\n",
    "    print(\"Got image from {}\".format(chat_id))\n",
    "\n",
    "    # получаем информацию о картинке\n",
    "    image_info = update.message.photo[-1]\n",
    "    image_file = bot.get_file(image_info)\n",
    "    image_stream = BytesIO()\n",
    "    image_file.download(out=image_stream)\n",
    "    print('load image')\n",
    "    class_ = model.predict1(image_stream)\n",
    "    \n",
    "    ans = 'я думаю это ' + str(class_) + ', но если ты хочешь добиться большей точности то сфоткай фрукт на белоим фоне'\n",
    "    # теперь отправим результат\n",
    "    update.message.reply_text(ans)\n",
    "    print(\"Sent Answer to user, predicted: {}\".format(class_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "InvalidToken",
     "evalue": "Invalid token",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidToken\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-ab7449339d18>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     10\u001b[0m          level=logging.INFO)\n\u001b[0;32m     11\u001b[0m     \u001b[1;31m# используем прокси, так как без него у меня ничего не работало(\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m     \u001b[0mupdater\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mUpdater\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtoken\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtoken\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m     \u001b[0mupdater\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatcher\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_handler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mMessageHandler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mFilters\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mphoto\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msend_prediction_on_photo\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[0mupdater\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatcher\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_handler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mMessageHandler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mFilters\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\telegram\\ext\\updater.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, token, base_url, workers, bot, private_key, private_key_password, user_sig_handler, request_kwargs)\u001b[0m\n\u001b[0;32m    127\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_request\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mRequest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mrequest_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    128\u001b[0m             self.bot = Bot(token, base_url, request=self._request, private_key=private_key,\n\u001b[1;32m--> 129\u001b[1;33m                            private_key_password=private_key_password)\n\u001b[0m\u001b[0;32m    130\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0muser_sig_handler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0muser_sig_handler\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    131\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate_queue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mQueue\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\telegram\\bot.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, token, base_url, base_file_url, request, private_key, private_key_password)\u001b[0m\n\u001b[0;32m    114\u001b[0m     def __init__(self, token, base_url=None, base_file_url=None, request=None, private_key=None,\n\u001b[0;32m    115\u001b[0m                  private_key_password=None):\n\u001b[1;32m--> 116\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoken\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_token\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtoken\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    117\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    118\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mbase_url\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\telegram\\bot.py\u001b[0m in \u001b[0;36m_validate_token\u001b[1;34m(token)\u001b[0m\n\u001b[0;32m    145\u001b[0m         \u001b[0mleft\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msep\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_right\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtoken\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpartition\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m':'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    146\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;32mnot\u001b[0m \u001b[0msep\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;32mnot\u001b[0m \u001b[0mleft\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misdigit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mleft\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 147\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mInvalidToken\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    148\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    149\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mtoken\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInvalidToken\u001b[0m: Invalid token"
     ]
    }
   ],
   "source": [
    "from PIL import Image as PIL_Image\n",
    "import matplotlib.pyplot as plt\n",
    "if __name__ == '__main__':\n",
    "    from telegram.ext import Updater, MessageHandler, Filters\n",
    "    import logging\n",
    "    import telegram\n",
    "    # Включим самый базовый логгинг, чтобы видеть сообщения об ошибках\n",
    "    logging.basicConfig(\n",
    "         format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',\n",
    "         level=logging.INFO)\n",
    "    # используем прокси, так как без него у меня ничего не работало(\n",
    "    updater = Updater(token=token)\n",
    "    updater.dispatcher.add_handler(MessageHandler(Filters.photo, send_prediction_on_photo))\n",
    "    updater.dispatcher.add_handler(MessageHandler(Filters.text, text))\n",
    "    updater.start_polling()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
